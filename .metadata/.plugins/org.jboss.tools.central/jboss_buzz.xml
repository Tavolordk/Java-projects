<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Quarkus 2, RESTEasy 4.6 fixes and more</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/tH7dK2zn5qw/" /><author><name /></author><id>https://resteasy.github.io/2021/07/06/resteasy-4.6.2.Final/</id><updated>2021-07-06T00:45:00Z</updated><dc:creator /><summary type="html">&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/tH7dK2zn5qw" height="1" width="1" alt=""/&gt;</summary><feedburner:origLink>https://resteasy.github.io/2021/07/06/resteasy-4.6.2.Final/</feedburner:origLink></entry><entry><title type="html">Apache Camel 3.11 What's New</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gkaO8XYtwO0/apache-camel-311-whats-new.html" /><author><name>Claus Ibsen</name></author><id>http://feedproxy.google.com/~r/ApacheCamel/~3/DYxmwGm8nIw/apache-camel-311-whats-new.html</id><updated>2021-07-04T18:57:00Z</updated><content type="html">Apache Camel 3.11 has just been released. This is a LTS release which will be supported for 1 year with regular patch and security releases. This blog post first details the noteworthy changes since the last 3.10 release from last month. For readers that are upgrading from the last 3.7 LTS release then we have added a summary section that highlights all the important new features and changes (3.7 to 3.11). At first what did we do since the 3.10 release. SO WHAT'S IN THIS RELEASE SINCE 3.10 This release introduces a set of new features and noticeable improvements that we will cover in this blog post. KAMELETS Kamelets is a higher level building blocks that we keep innovating and improve over the coming releases. For Camel 3.11 we worked on making Kamelets universal across the various runtimes such as standalone, Karaf, Spring Boot, and Quarkus. We added a new camel-kamelet-main component that is intended for developers to try out or develop custom Kamelets. This module runs standalone which is intentional as we want to ensure Kamelets are not tied to a specific runtime (or the cloud on Kubernetes) but are truly universal in any environment where you can use Camel. You can find an example with camel-kamelet-main at The YAML DSL has improved error reporting when parsing to better report to Camel end users where the problem is. COMMON SOURCE TIMESTAMP We added a `getSourceTimestamp` API on `Message` to get hold of the timestamp from the source of the message. The idea is to have a common API across all the Camel components that has a timestamp of the event (such as JMS, Kafka, AWS, File/FTP etc). CLOUD COMPONENT The Camel AWS, Azure, and HuaweiCloud components have had various bug fixes and smaller improvements. QUARKUS This release is the baseline for Quarkus 2 support which is to follow shortly after this release with a new Camel Quarkus release. SPRING BOOT We have upgraded to latest Spring Boot 2.5.1 release. NO OSGI CODE IN MAIN PROJECT We had about six remaining Camel components which had some special OSGi Java source code. The OSGi code has been ported over to the Camel Karaf project. BETTER JAVA 16 SUPPORT Although Java 16 is not officially supported, we did improve a few Camel components to make them work with Java 16. The official support is Java 11 (primary) and Java 8 (secondary). NEW COMPONENTS This release has a number of new components, data formats and languages: * camel-huaweicloud-functiongraph - To call serverless functions on Huawei Cloud * camel-huaweicloud-iam - To securely manage users on Huawei Cloud * camel-kamelet-main - Main to run Kamelet standalone * camel-resourceresolver-github - Resource resolver to load files from GitHub UPGRADING Make sure to read the if you are upgrading from a previous Camel version. RELEASE NOTES You can find more information about this release in the , with a list of JIRA tickets resolved in the release. SUMMARY OF CHANGES SINCE THE LAST 3.7 LTS RELEASE It is 6 months since the last 3.7 LTS release, and here is a high level summary of the most significant changes we have done: * Optimized core (faster startup and quicker routing engine) * Modularized core (even smaller core) * Reduced Object Allocations (lower memory footprint)   * Reflection free (Native compilation friendly) * Optimized toD EIP for messaging based components * Better startup and shutdown logging * Java Flight Recorder * Routes loader (Java, XML, YAML, Groovy, JavaScript, and Kotlin) * YAML DSL * Kamelets * 17 new components * Support for Spring Boot 2.5 and Quarkus 2.0 There are many other great new features and improvements that you can find detailed in each of the Whats New blog posts: * * *&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gkaO8XYtwO0" height="1" width="1" alt=""/&gt;</content><dc:creator>Claus Ibsen</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/DYxmwGm8nIw/apache-camel-311-whats-new.html</feedburner:origLink></entry><entry><title>Making Java programs cloud-ready, Part 4: Optimize the runtime environment</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6U-wqp9ynHw/making-java-programs-cloud-ready-part-4-optimize-runtime-environment" /><author><name>Mauro Vocale</name></author><id>129d919a-4527-4951-b9a0-c2fe66a425a4</id><updated>2021-07-02T07:00:00Z</updated><published>2021-07-02T07:00:00Z</published><summary type="html">&lt;p&gt;This is the final article in a series where we are updating a monolithic &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java EE&lt;/a&gt; application to function as a &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservice&lt;/a&gt; and run in a distributed cloud environment such as &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. In the first article, we set up the legacy Java application and defined our goals. Then, we upgraded the Java environment to &lt;a href="https://jakarta.ee/"&gt;Jakarta EE&lt;/a&gt;. In the last article, we used &lt;a href="https://microprofile.io/"&gt;MicroProfile&lt;/a&gt; to prepare the application for use in a distributed environment.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Read the whole series&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p class="Indent1"&gt;Part 1: &lt;a href="https://developers.redhat.com/articles/2021/06/25/making-java-programs-cloud-ready-part-1-incremental-approach-using-jakarta-ee"&gt;An incremental approach using Jakarta EE and MicroProfile&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p class="Indent1"&gt;Part 2: &lt;a href="https://developers.redhat.com/articles/2021/06/28/making-java-programs-cloud-ready-part-2-upgrade-legacy-java-application-jakarta"&gt;Upgrade the legacy Java application to Jakarta EE&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p class="Indent1"&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/06/30/making-java-programs-cloud-ready-part-3-integrate-microprofile-services"&gt;Integrate MicroProfile services&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Part 4&lt;/strong&gt;: Optimize the runtime environment&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;p&gt;We now have all the functionality we planned to add to our cloud-ready Java application. However, the resulting image is substantially larger than our initial image. This is not optimal because we'll need to transfer the image over the network and run it on a platform-as-a-service (PaaS) in the cloud. Resources such as memory, CPU, and RAM use factor into the costs charged by a PaaS provider. In this final article, we'll optimize the runtime to reduce the image's size and memory footprint. The benefits of optimizing the runtime include:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Better cloud-resource utilization.&lt;/li&gt; &lt;li&gt;Decreasing startup and scale-up time.&lt;/li&gt; &lt;li&gt;Minimizing the attack surface.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Runtime optimization with JBoss EAP, JBoss EAP XP, and Galleon&lt;/h2&gt; &lt;p&gt;We'll use &lt;a href="https://developers.redhat.com/products/eap/download"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP) and JBoss EAP XP to decrease the size of our application image while also increasing container security. First, we'll develop a runtime image that eliminates development tools (such as Maven artifacts) that were present in the original &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_software_collections/2/html/using_red_hat_software_collections_container_images/sti"&gt;Source-to-Image (S2I)&lt;/a&gt; environment. Then, we'll use &lt;a href="https://github.com/wildfly/galleon"&gt;Galleon&lt;/a&gt; to trim the application features and provide customization for JBoss EAP and its image’s footprint.&lt;/p&gt; &lt;p&gt;Note that we'll use the same &lt;a href="https://github.com/mvocale/JBoss_EAP_cloud_ready"&gt;GitHub repository&lt;/a&gt; we've used for the previous articles in the series. To start, switch to the &lt;code&gt;git&lt;/code&gt; tag that contains the source code used to implement the Galleon version:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ git checkout tags/Galleon_Runtime_version&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, delete the previous version of the application to start with a clean environment:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc delete all --selector app=weather-app-eap-cloud-ready $ oc delete is weather-app-eap-cloud-ready $ oc delete bc weather-app-eap-cloud-ready&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Import the image for the JBoss EAP XP 2.0 OpenJDK 11 runtime:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc import-image jboss-eap-7/eap-xp2-openjdk11-runtime-openshift-rhel8 --from=registry.redhat.io/jboss-eap-7/eap-xp2-openjdk11-runtime-openshift-rhel8 --confirm&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Update the buildConfig&lt;/h3&gt; &lt;p&gt;Now let's focus on the &lt;code&gt;buildConfig.yaml&lt;/code&gt; file under the &lt;code&gt;k8s&lt;/code&gt; directory. In that file, I defined a chained build with two &lt;code&gt;buildConfig&lt;/code&gt; objects: &lt;code&gt;weather-app-eap-cloud-ready-build-artifacts&lt;/code&gt; and &lt;code&gt;weather-app-eap-cloud-ready&lt;/code&gt;. The first one is the S2I builder image that contains a complete JBoss EAP server with tooling needed during the S2I build. The second one has the runtime image that contains dependencies needed to run JBoss EAP. The first build creates the JBoss EAP XP instance and the application to be deployed, whereas the second build excludes the development tools not needed in the production environment. Figure 1 summarizes the components of the development process and their relationships.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/build_components.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/build_components.png?itok=BPVGhr6S" width="600" height="277" alt="Diagram with the steps needed to obtain a runtime image." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Components of builds for our containerized application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Here is a snapshot of the chained build:&lt;/p&gt; &lt;pre&gt; &lt;code class="yaml"&gt;kind: ImageStream apiVersion: image.openshift.io/v1 metadata: name: weather-app-eap-cloud-ready-build-artifacts labels: application: weather-app-eap-cloud-ready-build-artifacts --- kind: ImageStream apiVersion: image.openshift.io/v1 metadata: name: weather-app-eap-cloud-ready labels: application: weather-app-eap-cloud-ready --- kind: BuildConfig apiVersion: build.openshift.io/v1 metadata: name: weather-app-eap-cloud-ready-build-artifacts namespace: redhat-jboss-eap-cloud-ready-demo labels: build: weather-app-eap-cloud-ready-build-artifacts spec: output: to: kind: ImageStreamTag name: 'weather-app-eap-cloud-ready-build-artifacts:latest' resources: {} strategy: type: Source sourceStrategy: from: kind: ImageStreamTag namespace: redhat-jboss-eap-cloud-ready-demo name: 'eap-xp2-openjdk11-openshift-rhel8:latest' source: type: Binary binary: {} --- kind: BuildConfig apiVersion: build.openshift.io/v1 metadata: labels: application: weather-app-eap-cloud-ready name: weather-app-eap-cloud-ready spec: output: to: kind: ImageStreamTag name: weather-app-eap-cloud-ready:latest source: dockerfile: |- FROM eap-xp2-openjdk11-runtime-openshift-rhel8 COPY /server $JBOSS_HOME USER root RUN chown -R jboss:root $JBOSS_HOME &amp;&amp; chmod -R ug+rwX $JBOSS_HOME USER jboss CMD $JBOSS_HOME/bin/openshift-launch.sh images: - from: kind: ImageStreamTag name: weather-app-eap-cloud-ready-build-artifacts:latest paths: - sourcePath: "/s2i-output/server/" destinationDir: "." strategy: dockerStrategy: imageOptimizationPolicy: SkipLayers from: kind: ImageStreamTag name: eap-xp2-openjdk11-runtime-openshift-rhel8:latest namespace: redhat-jboss-eap-cloud-ready-demo type: Docker triggers: - imageChange: {} type: ImageChange&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Switch JBoss EAP XP to bootable JAR mode&lt;/h3&gt; &lt;p&gt;We'll also need to configure JBoss EAP XP to run in a bootable JAR mode so that you can enable the runtime image. To configure this mode, I set the following environment variables in the &lt;code&gt;environment&lt;/code&gt; file under the &lt;code&gt;.s2i&lt;/code&gt; directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;#GALLEON_PROVISION_DEFAULT_FAT_SERVER=true GALLEON_PROVISION_LAYERS=jaxrs-server,microprofile-platform S2I_COPY_SERVER=true&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We can use the bootable JAR to build a bootable JAR application image, which contains a server, a packaged application, and the runtime required to launch the server. As shown in the YAML snippet, there are two properties related to the Galleon framework. The first one creates a bootable JAR with a full-featured JBoss EAP XP subsystem:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;GALLEON_PROVISION_DEFAULT_FAT_SERVER=true&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;But our target is not only to have a slim and more secure container image that omits unnecessary tools. We also want to improve the use of cloud resources by removing unused subsystems from JBoss EAP XP. For this reason, I commented out the &lt;code&gt;GALLEON_PROVISION_DEFAULT_FAT_SERVER&lt;/code&gt; property. To include only the necessary subsystems, I also set the &lt;code&gt;GALLEON_PROVISION_LAYERS&lt;/code&gt; property with the names of the subsystems needed to run my application. The &lt;code&gt;jaxrs-server&lt;/code&gt; subsystem provides support for JAX-RS and JPA, while the &lt;code&gt;microprofile-platform&lt;/code&gt; subsystem includes the MicroProfile capabilities we added in Part 3.&lt;/p&gt; &lt;p&gt;I also set the property &lt;code&gt;S2I_COPY_SERVER &lt;/code&gt;to copy the result of the first build, named &lt;code&gt;weather-app-eap-cloud-ready-build-artifacts&lt;/code&gt; in the &lt;code&gt;buildConfig.yaml&lt;/code&gt;, into the final runtime image as described in the &lt;code&gt;weather-app-eap-cloud-ready&lt;/code&gt; build, which is always set in the &lt;code&gt;buildConfig.yaml&lt;/code&gt; file. Without this property, you can't complete this step.&lt;/p&gt; &lt;h3&gt;Create the new runtime image&lt;/h3&gt; &lt;p&gt;Now it’s time to create the &lt;code&gt;ImageStreams&lt;/code&gt; and the chained &lt;code&gt;buildConfig&lt;/code&gt; to make the runtime image with JBoss EAP XP 2 and the application:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc create -f k8s/buildConfig.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, start the build of the application on OpenShift:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc start-build weather-app-eap-cloud-ready-build-artifacts --from-dir=. --wait&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I suggest that you check when the second build finishes with this command:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc get build weather-app-eap-cloud-ready-1 --watch&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After the status moves from &lt;code&gt;Pending&lt;/code&gt; to &lt;code&gt;Complete&lt;/code&gt;, you can create the weather application for JBoss EAP XP 2 and configure it:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ oc create -f k8s/weather-app-eap-cloud-ready.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can then test your application, using the steps I have described in the previous articles, to verify that it is still working.&lt;/p&gt; &lt;h2&gt;Reviewing the outcomes&lt;/h2&gt; &lt;p&gt;Now it’s time to check the return on investment for the operations we've just performed. Figure 2 shows the new container image size.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/optimized_summary.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/optimized_summary.png?itok=eOtwHTxn" width="600" height="188" alt="The size of the final, optmized image is only 294.6 MB." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Summary and size information after our upgrade to remove unneeded components. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Figure 3 shows the new memory footprint.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/optimized_memory.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/optimized_memory.png?itok=NwncFnza" width="600" height="40" alt="The final, optmized image uses only 718.9 MB of memory." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Memory use after our upgrade to remove unneeded components. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Consider these outcomes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Container image size&lt;/strong&gt;: The previous application image, with Jakarta EE and MicroProfile features plus all of JBoss EAP XP and RHEL 8 UBI, takes up &lt;em&gt;455 MB&lt;/em&gt;. The final image, obtained through the optimizations we carried out in this article, is &lt;em&gt;294 MB&lt;/em&gt;, a savings of &lt;em&gt;35%&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Memory footprint&lt;/strong&gt;: The previous application release, with Jakarta EE and MicroProfile features, plus all of JBoss EAP XP and RHEL 8 UBI, requires &lt;em&gt;1,000 MB&lt;/em&gt; of memory. The final release, obtained through optimization, requires &lt;em&gt;718 MB&lt;/em&gt; of memory, a savings of &lt;em&gt;28%&lt;/em&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Conclusion to Part 4&lt;/h2&gt; &lt;p&gt;This series has gone through the steps to modernize a legacy Java EE application using Jakarta EE and Eclipse MicroProfile. The resulting final application includes features and services that are beneficial for microservice applications running in the cloud. By repeating the processes shown in the series, you can break your monolithic Java applications into small and independent modules without needing to heavily change your source code. The resulting runtime environment is:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Optimized for the cloud and containers&lt;/li&gt; &lt;li&gt;Lightweight, with a flexible architecture&lt;/li&gt; &lt;li&gt;More productive for developers&lt;/li&gt; &lt;li&gt;Flexible in management, configuration, and administration&lt;/li&gt; &lt;li&gt;Oriented to supporting and standardizing microservices development&lt;/li&gt; &lt;li&gt;Based entirely on open source tools and standards&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Don’t stop evolving all of your applications! Continuous improvement is the key to the success of your architecture.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;More about modernization&lt;/strong&gt;: &lt;a href="https://developers.redhat.com/articles/2021/06/14/application-modernization-patterns-apache-kafka-debezium-and-kubernetes"&gt;Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/07/02/making-java-programs-cloud-ready-part-4-optimize-runtime-environment" title="Making Java programs cloud-ready, Part 4: Optimize the runtime environment"&gt;Making Java programs cloud-ready, Part 4: Optimize the runtime environment&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6U-wqp9ynHw" height="1" width="1" alt=""/&gt;</summary><dc:creator>Mauro Vocale</dc:creator><dc:date>2021-07-02T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/07/02/making-java-programs-cloud-ready-part-4-optimize-runtime-environment</feedburner:origLink></entry><entry><title type="html">How to start contributing to Drools Executable Model</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Mql1NTVjhu8/how-to-start-contributing-to-drools-executable-model.html" /><author><name>Luca Molteni</name></author><id>https://blog.kie.org/2021/07/how-to-start-contributing-to-drools-executable-model.html</id><updated>2021-07-01T13:45:17Z</updated><content type="html">WHAT IS THE EXECUTABLE MODEL? The Executable Model is a new way to execute business rules in Drools. It’s based on a Java representation of the rule structure that provides a few advantages such as faster startup time and better memory allocation at runtime. You can check out the details in the or in other blog posts such as . KJARs built with the kie-maven-plugin have the Executable Model enabled since 7.33.0.Final by default and it’s the main technology underneath . With the "Executable Model Compiler", a module you can find in the drools-model-compiler directory, DRL files are transformed into a Java DSL. HOW TO START CONTRIBUTING Drools is a really big open source project, and finding the best way to contribute to it might not be easy. Luckily, the Executable Model Compiler is a good way to start, for various reasons: * It’s a fairly new project (as today it’s been more or less three years since the inception) * It doesn’t require deep understanding of the Drools’ internal algorithm, PHREAK * There always is a former counterpart to verify the code against Regarding the third point, we want Drools to behave in the exact same way while using the former runtime (also called DRL) and the new one (called PatternDSL). CONTRIBUTING: SHOWING A PROBLEM Imagine that you’re interested in contributing to Drools, what should you do when you find a problem and you think it’s related to the Executable Model? Firstly we should understand where the problem is in Drools and if it’s eventually related to the Executable Model. To do that, we need to create the smallest piece of code that shows the problem: this is what we called a "bug reproducer" (also just "reproducer"). If you provide a bug report to , or the team will ask you to create such reproducer. There are two ways to do it: 1) If you’re familiar with the you can write the test directly in your own fork of the original repository and create a PR against it. This is probably the best way to proceed, as it allows all the Drools’ developers to check the problem faster 2) Create another separate project that shows the problem METHOD #1: CREATE A REPRODUCER IN DROOLS.GIT Start by building the Drools project reading the page. You can either decide to build it using or building only the module with mvn clean install. The second one is definitely faster. Once you have the project up and running you can open it with your preferred IDE and take a look at the tests in the drools-model-compiler module, for example org.drools.modelcompiler.CompilerTest. If you run these tests you’ll see they’re executed twice, once against the DRL mode and the other against the PatternDSL. It’s important that the tests run in both ways. If you see a difference in the execution, please create a PR. And if you want to fix it on your own, try – we love to see new contributors. METHOD #2: CREATE A SELF CONTAINED PROJECT Let’s use the Drools archetype and verify that your small reproducer is working against Drools Legacy. Start by creating a KJAR using the , modify the rules and the test to verify everything is working accordingly. The default archetype will run the test against the DRL mode. Change the generated model to build an executable model KJAR. To do so, switch in the pom.xml from drools-engine-classic to drools-engine. Also add the drools-model-compiler dependency. Compile the project using maven and the command line. Use mvn clean install -DskipTests=true as it’ll try run the tests using the classic engine but we don’t have the drools-mvel dependency in the class path anymore. Verify the Executable Model has been built in the KJAR, you can for example using this command to view the content inside the KJAR: jar -tf target/name_of_the_kjar.jar You will see all the Executable Model classes under and the drools-model file. Another way to do it is to check the maven log for this phrase: [INFO] Found 7 generated files in Canonical Model [INFO] Generating /Users/lmolteni/git/contribute/reproducer-kjar/target/generated-sources/drools-model-compiler/main/java/./org/example/P41/LambdaExtractor41A2683D222972683028514525A5437B.java ... Create another project called runner that has the original project as a dependency in the Maven pom.xml. The same archetype can be used again, but you have to change a few things * Remove all the classes in src/main/java * Remove the DRL files, as this project only consumes KJARs * Remove the kmodule.xml file * Remove the kie-maven-plugin from the build. Again, we don’t want to build KJARs here, only to use them. * Switch in the pom.xml from drools-engine-classic to drools-engine. * Remove the kjar packaging in pom.xml * Add the original KJAR dependency &lt;dependency&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;reproducer-kjar&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; * Move the test from the original reproducer to this module * Never call kContainer.verify(); while using Executable Model KJARs as this will retrigger the build Run the test. This time the test will run using the Executable Model. You can see it because there will be this line in the logs 2021-06-15 11:32:29,576 INFO [org.drools.modelcompiler.CanonicalKieModuleProvider] (main) Artifact org.example:reproducer-kjar:1.0-SNAPSHOT has executable model This can probably be abstracted in a new archetype, let us know if you’re interested and we can work of it. SUMMARY In this article, we saw how to provide a small reproducer to verify an unexpected behaviour in Drools Executable Model and to provide the developers some way to verify the unexpected behaviour. Please try and contribute to Drools Executable Model! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Mql1NTVjhu8" height="1" width="1" alt=""/&gt;</content><dc:creator>Luca Molteni</dc:creator><feedburner:origLink>https://blog.kie.org/2021/07/how-to-start-contributing-to-drools-executable-model.html</feedburner:origLink></entry><entry><title>How to expose a WebSocket endpoint using Red Hat 3scale API Management</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PdloXwnONXI/how-expose-websocket-endpoint-using-red-hat-3scale-api-management" /><author><name>Srikanth Valluru</name></author><id>e0eb6645-8d5f-48c5-a701-23e1da644d49</id><updated>2021-07-01T07:00:00Z</updated><published>2021-07-01T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://www.w3.org/TR/websockets/"&gt;WebSocket&lt;/a&gt; is a communications protocol that provides full-duplex communication channels to web servers and clients over a single TCP connection. The protocol was standardized by the World Wide Web Consortium (W3C) and has been in common use by web developers for more than a decade.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/3scale/overview"&gt;Red Hat 3scale API Management&lt;/a&gt; is a hosted environment for web applications. In this quick tip, you will see how to use 3scale to set up WebSocket communication easily. Figure 1 shows how 3scale mediates between the web client and the WebSocket interface on the server.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/3scale_relationships.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/3scale_relationships.png?itok=FQROWJnz" width="600" height="259" alt="The 3scale WebSockets policy stands between the client and server." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The relationship between the browser, 3scale, and the server. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This tip takes you through the following steps:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Setting up the WebSocket server.&lt;/li&gt; &lt;li&gt;Configuring 3scale API Management.&lt;/li&gt; &lt;li&gt;Using a WebSocket client to test the WebSocket endpoint.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Step 1: Set up the WebSocket server&lt;/h2&gt; &lt;p&gt;You can use any of your favorite frameworks to start the WebSocket server. For this article, we use &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;. (Installing Node.js is out of the scope of this tip.)&lt;/p&gt; &lt;p&gt;We'll also use a simple JavaScript program that sets up a WebSocket server, accepts a request, and sends a reply. You can save it as &lt;code&gt;index.js&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="javascript"&gt;// Minimal amount of secure websocket server var fs = require('fs'); // read ssl certificate var privateKey = fs.readFileSync('ssl-cert/key.pem', 'utf8'); var certificate = fs.readFileSync('ssl-cert/certificate.pem', 'utf8'); var credentials = { key: privateKey, cert: certificate }; var https = require('https'); //pass in your credentials to create an https server var httpsServer = https.createServer(credentials); httpsServer.listen(8443,"0.0.0.0"); var WebSocketServer = require('ws').Server; var wss = new WebSocketServer({ server: httpsServer }); wss.on('connection', function connection(ws) { ws.on('message', function incoming(message) { console.log('received: %s', message); ws.send('reply from server : ' + message) }); ws.send('something'); });&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can use Node.js to start the script:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;$ node index.js&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 2: Configure 3scale API Management&lt;/h2&gt; &lt;p&gt;Follow the 3scale documentation to add a back end and create the necessary metrics, products, and application plan to expose an endpoint. Provide the WebSocket server URL as the Private Base URL, as shown in Figure 2.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/private_base_url.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/private_base_url.png?itok=6HmnjAxN" width="600" height="116" alt="Enter the WebSocket server URL as the Private Base URL." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Enter the WebSocket server URL in the Private Base URL field. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Add your WebSockets policy to the policy chain, as shown in Figure 3. No configuration is needed inside the policy.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/policy_chain.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/policy_chain.png?itok=CtngE58j" width="479" height="241" alt="Using the 3scale dialog to define the policy chain." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Configuring the policy chain in 3scale. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Promote the endpoint to the staging API Gateway for testing. Figure 4 shows how the endpoint and mapping rules appear in the console.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/endpoint_mapping.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/endpoint_mapping.png?itok=tCNDAWdH" width="600" height="82" alt="Viewing the server's endpoint and mapping rules in the console." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: View the endpoint and mapping rules in the console. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Step 3: Use a WebSocket client to test the WebSocket endpoint&lt;/h2&gt; &lt;p&gt;A convenient client we use for testing in this example is the Chrome browser's &lt;a href="https://chrome.google.com/webstore/detail/web-socket-client/lifhekgaodigcpmnakfhaaaboididbdn"&gt;Web Socket Client extension&lt;/a&gt;. Enter the staging API Gateway URL and append the WebSocket public path to connect, as shown in Figure 5.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/test_url.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/test_url.png?itok=LSPvsFLt" width="600" height="140" alt="Testing a 3scale WebSocket connection by entering a URL." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: A sample URL for testing a 3scale WebSocket connection. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;3scale API Management offers policies to support communication between your front end and back end. See these resources for further information:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/installing_3scale/installing-apicast#websocket-protocol-support-for-apicast"&gt;WebSocket policy in 3scale&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/installing_3scale/installing-apicast#websocket-protocol-support-for-apicast"&gt;WebSocket protocol support for APIcast&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.8/html/administering_the_api_gateway/apicast_policies"&gt;Supported Policies in 3scale&lt;/a&gt; &lt;ul&gt;&lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/07/01/how-expose-websocket-endpoint-using-red-hat-3scale-api-management" title="How to expose a WebSocket endpoint using Red Hat 3scale API Management"&gt;How to expose a WebSocket endpoint using Red Hat 3scale API Management&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PdloXwnONXI" height="1" width="1" alt=""/&gt;</summary><dc:creator>Srikanth Valluru</dc:creator><dc:date>2021-07-01T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/07/01/how-expose-websocket-endpoint-using-red-hat-3scale-api-management</feedburner:origLink></entry><entry><title type="html">Cloud Adoption - Example adoption architecture</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/feWsgR4IXJI/cloud-adoption-example-adoption-architeccture.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/UQMoqclrSI0/cloud-adoption-example-adoption-architeccture.html</id><updated>2021-07-01T05:00:00Z</updated><content type="html">Part 3 - Example adoption architecture In our  from this series shared a look at the logical common architectural elements found in a cloud adoption solution for retail organisations. The process was laid out how we've approached the use case and how portfolio solutions are the base for researching a generic architecture.  It continued by laying out the process of how we've approached the use case by researching successful customer portfolio solutions as the basis for a generic architecture. Having completed our discussions on the logical view of the architecture, it's now time to look at a specific example. This article walks you through an example cloud adoption scenario showing how expanding the previously discussed elements provides an example for your own cloud adoption scenarios. ARCHITECTURE REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common architecture that was uncovered researching those solutions. It's our intent to provide guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architecture, but we've chosen a format that we hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this architecture and outline the solution for a cloud adoption architecture solution. CLOUD ADOPTION The key to this cloud adoption architecture is the focus on providing the ability to move workloads, be that traditional server hosted or more modern container hosted, from the traditional data center to private or pubic clouds as needed.  Keeping that in mind, this architecture starts on the far left with the generic elements showing how a core data center such as the development teams manage their production. They have their projects in a source code management (SCM) system, which makes use of a method to build out their applications and images shown as a server image build pipeline, and some form of an image store or registry for distribution across their architecture as needed. Moving to the right you encounter the destinations for these workloads, from the traditional physical data center, private cloud, to the representation of multiple possible public clouds. Closer examination of each destination shows a simplified generic RHEL host, which can be a physical, virtual, or container based machine along with the image registry used to manage the images for their particular destination as distributed by the central development image store. Next up, infrastructure management where we find the smart management element that's gathering input from all the deployed host machines from every destination and working together automation orchestration element to manage workloads. From the gained insights into your organisations workloads, it's possible to deploy new updates, manage security patching across all infrastructure destinations, roll out extra resources for surging demand on specific workloads, and so much more. The showcase model is that a workload is determined, based on organisational standards set by you, to be a candidate for migration from the physical data center to any one of the public clouds. This could be due to cost reductions that are achievable due to changes in public cloud offerings, or due to managing performance by putting a certain workload closer to the customers actual physical location. Finally, to assist with analysing the data provided by the running hosts, there are cloud services meant to help you manage responses and maintain your repository of automated actions. Over time your automation needs change such that you have a repository of actions you might want to take, which is managed by the enterprise operating automation element. These are fed to the infrastructure management elements for use across the organisation. Also over time you'll develop plans to react on certain insights as they happen and this collection of plans can be found in the insights platform that works through insight services to support the infrastructure management elements. As you can see, automating your cloud infrastructure requires insights based plans and actions that are distributed by management elements that monitor and initiate actions ensuring workloads are deploying to the right destinations for your organisational needs. CLOUD ADOPTION DATA This look at a cloud adoption architecture data flow is not meant to be an all encompassing view of the exact flow. The idea is to give an architecture that you use to understand how elements and their data works through the entire cloud adoption architecture. With that in mind, the data flow shown is from the core data center on the left and works its way through the image repositories (images), automation orchestration (playbooks), and smart management (packages). From the image registries in each destination the data shows rolling out the workloads and server images onto the RHEL hosts.  In the cloud services, data flows show the gathering of insights and distribution of the automation action along with recommendations for the smart management to apply across the entire organisations architecture. This concludes the look at the cloud adoption architecture.  WHAT'S NEXT This was just a short overview of the example adoption architecture that makes up our architecture for the cloud adoption use case.  An overview of this series on cloud adoption portfolio architecture: 1. 2. 3. Catch up on any past articles you missed by following any published links above. This completes the series and we hope you enjoyed this architecture for cloud adoption. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/feWsgR4IXJI" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/UQMoqclrSI0/cloud-adoption-example-adoption-architeccture.html</feedburner:origLink></entry><entry><title type="html">This Week in JBoss - 01 July 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DEnNmKSq2WA/weekly-2021-07-01.html" /><category term="quarkus" /><category term="DMN" /><category term="Drools" /><category term="Wildfly" /><category term="Infinispan" /><category term="microservices" /><author><name>Jason Porter</name><uri>https://www.jboss.org/people/jason-porter</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2021-07-01.html</id><updated>2021-07-01T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, DMN, Drools, Wildfly, Infinispan, microservices"&gt; &lt;h1&gt;This Week in JBoss - 01 July 2021&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello! Welcome to another edition of the JBoss Editorial that brings you news and updates from our community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Congrats to all the teams on their hard work!&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/blog/2021/06/29/infinispan-js-client"&gt;Inifinispan Node.js Client 0.9.0&lt;/a&gt; This was released last week and includes the ability for the Node.js client to connect with different SASL authentication mechanisms.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vertx.io/blog/eclipse-vert-x-4-1-1/"&gt;Eclipse Vert.x 4.1.1 released!&lt;/a&gt; Mostly bug fixes, but there were a few small features implemented. Check the announcement for more details.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-0-0-final-released/"&gt;Quarkus 2.0.0.Final released - Vert.x 4, MicroProfile 4, Continuous Testing and much more&lt;/a&gt;. Certainly a much anticipated release! Quarkus 2 has been in the works for months and the team is very excited for the release. A number of things have changed, so be sure to read the announcement and migration guide as you work on migrating those Quarkus apps!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_from_the_community"&gt;From the community&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Karina Varela has a post about &lt;a href="https://developers.redhat.com/articles/2021/06/24/automating-rule-based-services-java-and-kogito"&gt;automating rule-based services with Java and Kogito&lt;/a&gt; up on the Red Hat Developer Blog. The post focuses on Kogito and using it to build, package, and automate the deployment of those rule-based services on Kubernetes and OpenShift!&lt;/p&gt; &lt;p&gt;James Falkner quickly tackles &lt;a href="https://developers.redhat.com/articles/2021/07/01/resteasy-reactive-and-more-quarkus-20"&gt;RESTEasy Reactive in Quarkus 2.0&lt;/a&gt; over on the Red Hat Developer Blog. With the release of Quarkus 2.0 there are a number of things that have improved. Using REST in a reactive way is one of them. Quarkus 2.0 utilizes Eclipse Vert.x 4 and does some optimizations at build time to further increase performance of REST services.&lt;/p&gt; &lt;p&gt;If you’re using Red Hat 3scale API Management and have a need to use WebSockets, be sure to check out Srikanth Kalluru’s &lt;a href="https://developers.redhat.com/articles/2021/07/01/how-expose-websocket-endpoint-using-red-hat-3scale-api-management"&gt;blog post&lt;/a&gt; for a quick three step walk through of how to get it done!&lt;/p&gt; &lt;p&gt;Mauro Vocale has a three part series, part four is not out yet, about moving Java programs to the cloud. &lt;a href="https://developers.redhat.com/articles/2021/06/25/making-java-programs-cloud-ready-part-1-incremental-approach-using-jakarta-ee"&gt;Part one&lt;/a&gt; introduces you to the legacy application and gets it up and running on OpenShift. This gets you familiar with what the application does and what to expect from further refactorings in subsequent posts. In &lt;a href="https://developers.redhat.com/articles/2021/06/28/making-java-programs-cloud-ready-part-2-upgrade-legacy-java-application-jakarta"&gt;part two&lt;/a&gt; the application will move from Java 8 to Java 11, JBoss EAP 7.3 and Jakarta EE. Lastly, in &lt;a href="https://developers.redhat.com/articles/2021/06/30/making-java-programs-cloud-ready-part-3-integrate-microprofile-services"&gt;part three&lt;/a&gt; the application will be moved to microservices. Additional monitoring tools will be introduced including Prometheus and Jaeger. The application will be updated for handling restarts, health checks, and other configuration settings.&lt;/p&gt; &lt;p&gt;Over in the BPM arena, there are three posts to take a look at: &lt;a href="https://blog.kie.org/2021/06/custom-logic-in-bpmn.html"&gt;Custom logic in BPMN&lt;/a&gt; by Kirill Gaevksii, &lt;a href="https://blog.kie.org/2021/07/how-to-start-contributing-to-drools-executable-model.html"&gt;How to start contributing to Drools executable model&lt;/a&gt; where Luca Molteni discusses getting your feet with contributing to Drools’s "Executable Model Compiler". Lastly, Matteo Mortari discusses &lt;a href="https://blog.kie.org/2021/06/intelligent-kafka-message-routing-using-drools-dmn-engine-and-apache-camel.html"&gt;using Drools DMN and Apache Camel to intelligently route Kafka messages&lt;/a&gt;. It includes a video as well as various examples and code to really sink your teeth into.&lt;/p&gt; &lt;p&gt;Wildfly 24.0.0.Final includes a preview of Jakarta EE 9.1 features. Jeff Mesnil discusses &lt;a href="https://www.wildfly.org//news/2021/07/01/wildfly-preview-bootable-jar/"&gt;how to try these features out using a bootable jar&lt;/a&gt;. There’s also a section about getting up and running using OpenShift!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_developers_on_film"&gt;Developers on film&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Get your popcorn ready and sit back to watch some videos from our community. Here are my top picks for this week’s editorial:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=JOv1K_wj6Vo"&gt;Quarkus Insights #54: Kotlin on Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=WyeaF2pk8Ec"&gt;Quarkus Insights #55: Quarkus 2.0 Launch&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=HQHjrf3i91Q"&gt;KIE Live #36: How to play with DMN&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pj8or38w2eQ"&gt;KIE Live #37: How to work with dashboards layouts&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/jason-porter.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Jason Porter&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DEnNmKSq2WA" height="1" width="1" alt=""/&gt;</content><dc:creator>Jason Porter</dc:creator><feedburner:origLink>https://www.jboss.org/posts/weekly-2021-07-01.html</feedburner:origLink></entry><entry><title>Implementing Apache ActiveMQ-style broker meshes with Apache Artemis</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/2T4i68jSbSU/implementing-apache-activemq-style-broker-meshes-apache-artemis" /><author><name>Kevin Boone</name></author><id>2cfadff9-d418-49ea-a0f1-0c1aef7314a7</id><updated>2021-06-30T07:00:00Z</updated><published>2021-06-30T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://activemq.apache.org/"&gt;Apache ActiveMQ&lt;/a&gt; and &lt;a href="http://people.apache.org/~clebertsuconic/"&gt;Apache Artemis&lt;/a&gt; (or ActiveMQ Artemis) are open source message brokers with similar functionality. Both implementations are venerable, with histories that go back to the early 2000s. However, Artemis is in some senses a more modern implementation because, ironically, it has a smaller feature set. This makes Artemis easier to maintain, which is important if you're basing a commercial product on it. The smaller feature set means a smaller overall implementation, which fits well with developing &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Early versions of &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ&lt;/a&gt; were based on ActiveMQ, but attention has shifted to Artemis in &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.1/html/introducing_red_hat_amq_7/index"&gt;AMQ 7&lt;/a&gt;. ActiveMQ is not maintained as vigorously as it once was by the open source community, but at the time of writing, Amazon is still offering a message broker service based on ActiveMQ. Whether it has a long-term future, at Amazon or elsewhere, remains to be seen.&lt;/p&gt; &lt;p&gt;Leaving aside ActiveMQ's complex niche features (such as message routing based on Apache Camel rules), ActiveMQ and Artemis look similar to the integrator and, in most practical applications, provide comparable throughput. However, they differ in important areas. Message distribution in the presence of multiple active brokers causes particular problems for integrators who want to move from ActiveMQ to Artemis.&lt;/p&gt; &lt;p&gt;This article describes subtleties that can lead to lost messages in an Artemis &lt;em&gt;active-active&lt;/em&gt; mesh. That architecture consists of multiple message brokers interconnected in a mesh, each broker with its own message storage, where all are simultaneously accepting messages from publishers and distributing them to subscribers. ActiveMQ and Artemis use different policies for message distribution. I will explain the differences and show a few ways to make Artemis work more like ActiveMQ in an active-active scenario.&lt;/p&gt; &lt;h2&gt;Configuring the Artemis broker mesh&lt;/h2&gt; &lt;p&gt;For simplicity, I'm assuming that the brokers in the mesh have network names like broker1, broker2, etc., and that each listens for all messaging protocols on port 61616 (this is the default for Artemis as well as ActiveMQ). The setup I describe below is for broker1, but there is a high degree of symmetry between the brokers, so it isn't hard to work out the other broker settings.&lt;/p&gt; &lt;p&gt;When creating a new broker, the usual approach is to run &lt;code&gt;artemis create brokerXXX&lt;/code&gt; to create an outline configuration. I'm assuming that you have done this initial configuration, and so only mesh-related configuration has to be added to &lt;code&gt;etc/broker.xml&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;The acceptor definition&lt;/h3&gt; &lt;p&gt;Every Artemis broker has at least one &lt;code&gt;acceptor&lt;/code&gt; definition that defines the TCP port and the protocols that will be accepted on that port. There's probably nothing different about this definition in a broker mesh, compared to a standalone broker. Here's an example, for a broker that accepts all wire protocols on port 61616:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;&lt;acceptor name="artemis"&gt;tcp://0.0.0.0:61616? protocols=CORE,AMQP,STOMP,HORNETQ,MQTT,OPENWIRE/&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In practice, an acceptor that handles multiple protocols will probably have a lot of additional configuration, but that's not really relevant here. In any case, the instance-creation step will already have created an outline entry. You'll need to change it only if you want a specific configuration, such as using different network interfaces for client and interbroker communication.&lt;/p&gt; &lt;h3&gt;The connectors&lt;/h3&gt; &lt;p&gt;Next, we need to define connectors. These are equivalent to the network connector definitions in ActiveMQ, but there is one significant difference: With Artemis, we usually define the broker itself as a connector. Here is an example:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;connectors&gt; &lt;connector name="myself"&gt;tcp://broker1:61616&lt;/connector&gt; &lt;connector name="broker2"&gt;tcp://broker2:61616&lt;/connector&gt; &lt;connector name="broker3"&gt;tcp://broker3:61616&lt;/connector&gt; &lt;/connectors&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first entry, &lt;code&gt;myself&lt;/code&gt;, denotes the current broker with its hostname and port. Subsequent entries define the other brokers in the mesh. For symmetry, I could have given the self-referential connector the name &lt;code&gt;broker1&lt;/code&gt;, to match the other brokers that follow. This naming approach may be useful if you have a large mesh and you want to cut and paste your configuration from one broker to another. However, sometimes it is clearer to make the self-referential connector stand out in some way. In any case, the important point is to define connectors for every broker in the mesh, including this one.&lt;/p&gt; &lt;h3&gt;The broker mesh&lt;/h3&gt; &lt;p&gt;The final vital piece of configuration assembles the various broker connectors into a mesh. Artemis provides various discovery mechanisms by which brokers can find one another in the network. However, if you're more familiar with ActiveMQ, you're probably used to specifying the mesh members explicitly. The following example shows how to do that, for the connectors listed in the configuration just shown. Note that I'm referring to this broker itself as &lt;code&gt;myself&lt;/code&gt;, to match the previous connector definition. It would be a mistake to list the current broker as a cluster connection, which is why I prefer to use a distinctive name.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;cluster-connections&gt; &lt;cluster-connection name="my_mesh"&gt; &lt;connector-ref&gt;myself&lt;/connector-ref&gt; &lt;message-load-balancing&gt;ON_DEMAND&lt;/message-load-balancing&gt; &lt;static-connectors&gt; &lt;connector-ref&gt;broker2&lt;/connector-ref&gt; &lt;connector-ref&gt;broker3&lt;/connector-ref&gt; &lt;/static-connectors&gt; &lt;/cluster-connection&gt; &lt;/cluster-connections&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: I'll have more to say about &lt;code&gt;message-load-balancing&lt;/code&gt; later.&lt;/p&gt; &lt;p&gt;You'll probably want to configure your clients to know about the mesh, as well. Again, Artemis provides a number of discovery mechanisms, allowing clients to determine the network topology without additional configuration. These don't work with all wire protocols (notably, there is no discovery mechanism for Advanced Message Queuing Protocol), and ActiveMQ users are probably familiar with configuring the client's connection targets explicitly. The usual mechanism is to list all the brokers in the mesh in the client's connection URI.&lt;/p&gt; &lt;h2&gt;Why the Artemis configuration isn't (yet) like ActiveMQ&lt;/h2&gt; &lt;p&gt;With the configuration in the previous section, you should have a working mesh. That is, you should be able to connect consumers to all the nodes, produce messages to any node, and have them routed to the appropriate consumer. However, this mesh won't behave exactly like ActiveMQ, because &lt;em&gt;Artemis mesh operation is not governed by client demand&lt;/em&gt;.&lt;/p&gt; &lt;h3&gt;Forwarding behavior&lt;/h3&gt; &lt;p&gt;In ActiveMQ, network connectors are described as "demand forwarding." This means that messages are accepted on a particular broker and remain there until a particular client requests them. If there are no clients for a particular queue, messages remain on the original broker until that situation changes.&lt;/p&gt; &lt;p&gt;On Artemis, forwarding behavior is controlled &lt;em&gt;by the brokers&lt;/em&gt;, and is only loosely associated with client load. In the previous section's configuration, I set &lt;code&gt;message-load-balancing=ON_DEMAND&lt;/code&gt;. This instructs the brokers not to forward messages for specific queues to brokers where there are, at present, no consumers for those queues. So if there are no consumers connected at all, the routing behavior is similar to that of ActiveMQ: Messages will accumulate on the broker that originally received them. If I had set &lt;code&gt;message-load-balancing=STRICT&lt;/code&gt;, the receiving broker would have divided the messages evenly between the brokers that defined that queue. With this configuration, the presence or absence of clients &lt;em&gt;should&lt;/em&gt; be irrelevant ... except it isn't quite that simple, and the complications are sometimes important.&lt;/p&gt; &lt;h3&gt;How the message queue is defined&lt;/h3&gt; &lt;p&gt;Even with &lt;code&gt;STRICT&lt;/code&gt; load balancing, brokers won't forward messages to other brokers that don't know about the queue. If queues are administratively defined, all brokers know about all queues and accept messages for them in &lt;code&gt;STRICT&lt;/code&gt; mode. If the queues are auto-created by clients, and there are no clients for a specific queue, a producer on broker1 could send a message for a queue that was not known on broker2. As a result, messages would never be forwarded. In short: &lt;em&gt;It makes a difference whether a queue is defined administratively or auto-created&lt;/em&gt;. There is no such difference in message distribution in ActiveMQ, because it is driven by client demand.&lt;/p&gt; &lt;p&gt;Even with &lt;code&gt;ON_DEMAND&lt;/code&gt; load balancing, Artemis's behavior is not the same as ActiveMQ's. A particular difference is that message distribution decisions are made when the message arrives. It is at that point that the broker sees what clients are connected and routes the message as it deems appropriate. If there are no clients for a specific queue &lt;em&gt;at that time&lt;/em&gt;, the message will not be routed.&lt;/p&gt; &lt;p&gt;What this means is that if a client that is connected to broker1 goes down for some reason, and then reconnects, it will not receive any of the messages that came in the meantime. Even if there are no other clients for that queue on any other broker, the message will not be routed from its original location. It's too late—the routing decision has already been made.&lt;/p&gt; &lt;p&gt;This is a particular problem for broker installations that are behind a load balancer or similar proxy. There's usually no way of knowing which broker a client will ultimately connect to because the load balancer will make that decision. But if a client has the bad fortune to get connected to a broker that has never hosted that client before, no messages that came earlier will be routed to it, even if it subscribes to a queue that has messages on some other broker. To fix this problem, we need &lt;em&gt;message redistribution&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;Message redistribution in Artemis&lt;/h2&gt; &lt;p&gt;ActiveMQ has no need for a message redistribution mechanism, because all message flows over the network connectors are coordinated by client demand. As we've seen, this is not the case for Artemis, where all message distribution is controlled by the brokers. In the usual run of events, distribution decisions are made when messages arrive, and they are irrevocable.&lt;/p&gt; &lt;p&gt;Artemis does have a way to redistribute messages after that point, but it is not enabled by default. The relevant setting is made on a specific address, or group of addresses, like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;address-setting match="#"&gt; &lt;redistribution-delay&gt;1000&lt;/redistribution-delay&gt; ... &lt;/address-setting&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The value supplied for &lt;code&gt;redistribution-delay&lt;/code&gt; is in units of milliseconds. This value is the length of time for which a broker will leave messages on a specific address that has no consumer, before sending them somewhere else. The default value is -1, meaning "do not redistribute.""&lt;/p&gt; &lt;p&gt;A redistribution delay of seconds or minutes, rather than milliseconds, probably creates less load on the broker and the network. In short, if you set an &lt;code&gt;ON_DEMAND&lt;/code&gt; load-balancing policy, and enable message redistribution with a relatively short delay, the broker mesh will largely look to clients like an ActiveMQ mesh.&lt;/p&gt; &lt;h2&gt;Why the Artemis configuration still isn't (exactly) like ActiveMQ's&lt;/h2&gt; &lt;p&gt;We have started to solve the problem of lost messages on Artemis. There are a number of subtle differences between Artemis and ActiveMQ, however, and it's impossible to get &lt;em&gt;exactly&lt;/em&gt; the same behavior that ActiveMQ implements.&lt;/p&gt; &lt;h3&gt;Message selectors&lt;/h3&gt; &lt;p&gt;A particular problem involves message selectors. If a client subscribes to a queue using a selector, it expects to receive only messages that match the selector. But what happens if different clients subscribe to the same queue, with different selectors, on different brokers? This is a rather specific problem, but it does come up. Artemis forwards messages according to whether there are consumers, not according to whether there are selectors. So there's every chance that messages will get forwarded to a broker whose consumers will not match the selector. These messages will never be consumed.&lt;/p&gt; &lt;p&gt;This isn't specifically an Artemis problem: Using selectors is somewhat problematic with a broker mesh, regardless of the implementation. Using selectors with a mesh isn't entirely robust on ActiveMQ, either: The broker has to maintain a "selector cache" to keep track of which selectors are active on which queues. Because it's impossible for the broker to know when clients come and go, the selector cache has to maintain tracking data for an extended period of time—perhaps indefinitely. This creates a memory burden, and as a result, there are different selector cache implementations available with different properties.&lt;/p&gt; &lt;p&gt;Artemis does not use selector caches, because it side-steps the issue of selector handling altogether. Unless your clients are configured to consume from all brokers concurrently (which isn't a bad idea in many applications), it's just not safe to use selectors.&lt;/p&gt; &lt;h3&gt;Message grouping&lt;/h3&gt; &lt;p&gt;There are a number of other broker features that don't work properly in a mesh, and don't work properly with ActiveMQ, either. The most troublesome is message grouping, which doesn't work at all in an Artemis mesh. It works partially with ActiveMQ, but isn't robust in the event of a client or broker outage. "Exclusive consumers" are also problematic on both brokers.&lt;/p&gt; &lt;p&gt;Recognizing the limitations described in this section, Red Hat is working on enhancements to Artemis that will allow brokers to re-route client connections to the brokers that are best placed to handle them. The work required is extensive because each of the various wire protocols that Artemis supports has its own way of dealing with dynamic load balancing.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;In a broker mesh, Artemis uses a completely different strategy for message distribution from ActiveMQ. Understanding how Artemis works in this respect should go a long way to determining what changes need to be made to move from ActiveMQ to Artemis.&lt;/p&gt; &lt;p&gt;In particular, use the &lt;code&gt;ON_DEMAND&lt;/code&gt; load-balancing policy, and be sure to enable message redistribution. Some tuning may be needed to find the best redistribution delay for a particular application.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/06/30/implementing-apache-activemq-style-broker-meshes-apache-artemis" title="Implementing Apache ActiveMQ-style broker meshes with Apache Artemis"&gt;Implementing Apache ActiveMQ-style broker meshes with Apache Artemis&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/2T4i68jSbSU" height="1" width="1" alt=""/&gt;</summary><dc:creator>Kevin Boone</dc:creator><dc:date>2021-06-30T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/06/30/implementing-apache-activemq-style-broker-meshes-apache-artemis</feedburner:origLink></entry><entry><title type="html">Quarkus 2.0.0.Final released - Vert.x 4, MicroProfile 4, Continuous Testing and much more</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Etd88sNTsro/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-2-0-0-final-released/</id><updated>2021-06-30T00:00:00Z</updated><content type="html">The Quarkus team is proud to announce the availability of the Final release of Quarkus 2.0. This version has been a gigantic effort to bring Quarkus to a whole new level, while keeping its roots: fast boot, low memory usage and developer joy. A big thank you to everyone involved...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Etd88sNTsro" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-2-0-0-final-released/</feedburner:origLink></entry><entry><title type="html">Infinispan Node.js client supports authentication</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VdaKbTVijgA/infinispan-js-client" /><author><name>Katia Aresti</name></author><id>https://infinispan.org/blog/2021/06/29/infinispan-js-client</id><updated>2021-06-29T12:00:00Z</updated><content type="html">NODE.JS CLIENT 0.9.0 Infinispan Node.js client version 0.9.0 was released last week with added support for different SASL authentication mechanisms. Up to now, our Node.js client could connect to Infinispan Server security realms with disabled authentication. DIGEST-MD5 Uses the MD5 hashing algorithm in addition to nonces to encrypt credentials. SCRAM Uses salt values in addition to hashing algorithms and nonce values to encrypt credentials. Hot Rod endpoints support SCRAM-SHA-1, SCRAM-SHA-256, SCRAM-SHA-384, SCRAM-SHA-512 hashing algorithms, in order of strength. EXTERNAL Uses client certificates to provide valid identities to Infinispan Server and enable encryption. OAUTHBEARER Uses tokens obtained via an OAuth 2.0 provider to securely connect to Infinispan Server. PLAIN: Sends credentials in plain text (unencrypted) over the wire in a way that is similar to HTTP BASIC authentication. Warning To secure Infinispan credentials, you should use PLAIN authentication only in combination with TLS encryption. RUN THE INFINISPAN SERVER Run the Infinispan Server with Docker or Podman docker run -it -p 11222:11222 -e USER="admin" -e PASS="password" quay.io/infinispan/server:12.1 podman run -it -p 11222:11222 -e USER="admin" -e PASS="password" --net=host quay.io/infinispan/server:12.1 Important If you are using Docker for Mac, there is a known limitation. You will need to and run the server manually. Run the Infinispan Server from the file system ./bin/cli.sh user create admin -p password ./bin/server.sh CREATE A CACHE FROM INFINISPAN CONSOLE Access the Infinispan Console in and create a text based cache, named it 'my-cache' with the provided configuration. Connect to Infinispan { "distributed-cache": { "mode": "SYNC", "encoding": { "media-type": "text/plain" }, "statistics": true } } USE THE NODE.JS CLIENT IN YOUR APPLICATION Add the dependency to your project. package.json "dependencies": { "infinispan": "^0.9.0" } Configure the Infinispan Node.js client to connect with authentication and then check the created cache entry from the console. application.js var connected = infinispan.client({port: 11222, host: '127.0.0.1'}, { cacheName: 'my-cache', authentication: { enabled: true, saslMechanism: 'DIGEST-MD5', userName: 'admin', password: 'password' } }); connected.then(function (client) { return client.put('key', 'value') .finally(function() { return client.disconnect(); }); }); TO GO FURTHER Full client documentation is now available in the . Jira tracker for this client is available .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VdaKbTVijgA" height="1" width="1" alt=""/&gt;</content><dc:creator>Katia Aresti</dc:creator><feedburner:origLink>https://infinispan.org/blog/2021/06/29/infinispan-js-client</feedburner:origLink></entry></feed>
